---
title: "Targeted Marketing"
author: "Isidoro Garcia"
date: "2021"
output: pdf_document
graphics: yes
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA, message = FALSE,
                      fig.width = 6, fig.height = 4.5, fig.align = "right", cache = T)
```

\setlength{\parskip}{6pt}


## Overview

Los contratan como data scientists para una empresa que vende electrodomesticos. La empresa lanzó un experimento de control aleatorio via un mail en donde se envió un catalogo de los productos al grupo de tratamiento `mailing_indicator`. 

Tu objetivo es estimar el impacto del envío sobre el gasto incremental: 

$$\tau_{i}=\mathbb{E}[Y_{i}(1)-Y_{i}(0)|\boldsymbol{x}_{i}],$$

En particular, queremos estimar el impacto de enviar el catalogo a nivel de cliente. Para ello, pondremos a competir algunos de los modelo de Causal Machine Learning que hemos aprendido en clase: 

- Double Debiased Machine Learning 

- Causal Forests 

Adicionalmente, desarrollen una estrategia de focalización con base en los resultados de tu modelo. Elabora sobre la lógica económica (i.e. identifica los Beneficios y Costos Marginales de enviar la campaña). Finalmente, corrobora la validez externa de la estrategia usando datos de un año. Esto nos dará un termómetro de la utilidad del modelo para campañas posteriores. 

Tip!: En los chunks donde vaya a haber modelos o cálculos complicados, usen `cache=T`

## Paso 1: Estimación y predicción the Conditional Average Treatment Effects (CATE)

Carguemos los datos de 2015

```{r}
library(tidyverse)
library(data.table)
library(gamlr)
library(grf)
library(xgboost)
library(ranger)
library(RCT)
library(lfe)
library(stargazer)
library(knitr)
library(kableExtra)
```

```{r, cache=TRUE}
load("Bases input/Customer-Development-2015.RData")
```

Dividimos la base en entrenamiento y validacion. Usamos un seed fijo para replicabilidad.

```{r}
set.seed(1990)
crm<-
  crm %>% 
  mutate(training_sample = rbinom(n = nrow(crm), 1, 0.7))
  
```


#### Data cleaning

1. Haz una primera revisión de la base. Cuantas variables tienen `NA`
```{r}
mssng <- as.data.frame(sapply(crm, function(x) sum(is.na(x))))
colnames(mssng) <- c("MV")
mssng2 <- subset(mssng, MV > 0)
colnames(mssng2) <- c("Número de Missing Values")
kbl(mssng2, booktabs = T, caption = "<center><strong>Missing Values de las variables</strong></center>") %>%
kable_classic_2(full_width = F, html_font = "Cambria", fixed_thead = T)
```

No encontramos variables que tengan NA

###NO SE PORQUE NO ME APARECE NADA EN LA TABLA, PERO CON ESTE CÓDIGO SI, UTILIZANDO EL MISMO FORMATO QUE DANI ###
### No te aparece nada porque estás tabulando mssng2, que es el el subset de variables con MV positivos...y como no hay ninguna, pues no aparece nada.
#por otra parte, no creo que sea necesario presentar la tabla de 156 variables, que muestran que todas tienen 0 NAs, podemos solo comentarlo.
```{r}
tabla1<-apply(is.na(crm), 2, mean)
library(kableExtra)
library(knitr)
kbl(tabla1, booktabs = T, caption = "<center><strong>Missing Values de las variables</strong></center>") %>%
kable_classic_2(full_width = F, html_font = "Cambria", fixed_thead = T)
```
####QUEDA SUPEEEER PENDIENTE REVISAR LO DE LOS 0'S########


2. Muestra la matriz de correlación entre variables. Muestra los pares de variables que tienen más de 95% de correlación. Remueve una de cada par multicolineal. 

# Verificamos que todas las variables sean numéricas
tipo<-as.data.frame(sapply(crm, class))

# Calculamos la matriz de correlaciones
correlaciones <- cor(crm %>% select(-customer_id,-training_sample))

# Identificamos las variables con las correlaciones más altas y las mostramos
ordenado<-as.data.frame(as.table(correlaciones))
ordenado<-subset(ordenado,abs(Freq)>0.95)
ordenado<-subset(ordenado,Var1!=Var2)
colnames(ordenado) <- c("Var1","Var2","corr")

kbl(ordenado, booktabs = T, caption = "<center><strong>Pares con correlación>95%</strong></center>") %>% kable_classic_2(full_width = F, html_font = "Cambria", fixed_thead = T)

# Eliminamos una variable de cada par multicolineal

crm <- select(crm, -acquisition_months_since,-in_database_months,-emails_days_2yr,-customer_type_3,-emailview_6m,-spend_online_attributed_target)

```
Se eliminaron las siguientes variables por multicolinealidad: acquisition_months_since,in_database_months, emails_days_2yr, customer_type_3, emailview_6m, spend_online_attributed_target

3 (2 pts). Corroba que la asignación tratamiento fue aleatoria mediante revisión del balance. Realiza las pruebas balance T y F. Cuántas variables salen desbalanceadas? Que muestra esto sobre la asignación de tratamiento?
```{r}
# Generamos la tabla de balance para todas las x's (sin customer_id ni outcome_spend) e identificamos las variables desbalanceadas (para las que se rechaza la prueba T)

tabla <- balance_table(select(crm,-customer_id,-outcome_spend), treatment="mailing_indicator")
desbalance<-subset(tabla,p_value1<0.05)

kbl(desbalance, booktabs = T, caption = "<center><strong>Variables desbalanceadas</strong></center>") %>% kable_classic_2(full_width = F, html_font = "Cambria", fixed_thead = T)

# Prueba F
regress <- balance_regression(select(crm,-customer_id,-outcome_spend), treatment="mailing_indicator")
efe<-regress$F_test

kbl(efe, booktabs = T, caption = "<center><strong>Prueba F</strong></center>") %>% kable_classic_2(full_width = F, html_font = "Cambria", fixed_thead = T)

### Las variables que salen desbalanceadas son:
-clicks_product_type_201_1m
-customer_type_L
-dollars_season_C
-orders_3yr
-orders_attributed_mail_type_C
-orders_c
-orders_d_1yr
-orders_online_1yr
-orders_online_s_1yr
-orders_season_E
-orders_total
-spend_a_1yr
-spend_attributed_mail_type_C
-spend_d_s_1yr
-spend_instore_p_1yr
-spend_notz_1yr
-spend_online_a_1yr
-spend_online_a_3yr
-spend_online_b_1yr
-spend_online_b_3yr
-spend_online_g_1yr
-spend_online_s_1yr
-spend_period_1b
-spend_season_C
```

El valor-p de la prueba F es suficientemente grande, por lo que no se rechaza la hipótesis de que las covariables no explican la Pr de pertenecer al tratamiento, lo cual nos da evidencia de que la asignación es aleatoria.

No obstante, con una significancia de 5%, salen 24 variables desbalanceadas, es decir, el 16% de las variables, lo cual podría indicar que la asignación del tratamiento no fue completamente aleatoria.

4. Realize un ajuste de False Discovery Rate al 10%. Cuántas variables salen desbalanceadas ahora? 


```{r}
# Regresión
fit <-lm(outcome_spend~.-customer_id-training_sample, data = crm)

# FDR
library(broom)
resultados<-tidy(fit)

resultados<-
  resultados%>%
  arrange(p.value)%>%
  mutate(ranking =row_number())

resultados<-
  resultados%>%
  mutate(corte_fdr = 0.1*ranking/nrow(resultados),sig_fdr =if_else(p.value<=corte_fdr,'Significativa','No significativa'))

# Identificamos cúantas variables significativas están desbalanceadas

resultados<-subset(resultados,sig_fdr=="Significativa")

var_desbal<-desbalance$variables1
var_signif<-resultados$term
new_desbalance<-as.data.frame(intersect(var_desbal,var_signif))

kbl(new_desbalance, booktabs = T, caption = "<center><strong>Variables significativas desbalanceadas</strong></center>") %>% kable_classic_2(full_width = F, html_font = "Cambria", fixed_thead = T)

```
Hay 12 variables desbalanceadas.


### Estimación de impacto de tratamiento (ATE)

5 (2pts). Estima el impacto promedio de enviar el catalogo vía email. Estima el impacto sin controles y luego agregar dos estimaciones de robustez: 1) Agregando variables que salieron significativas y 2) Agregando variables que salieron significativas con el FDR. Interpreta los resultados 

```{r}
# Estimación del impacto promedio de enviar el catálogo vía email sobre el gasto incremental (SIN CONTROLES)

itt1<-impact_eval(data = crm,endogenous_vars =c("outcome_spend"),treatment = "mailing_indicator")
itt1<-as.data.frame(itt1)

kbl(itt1, booktabs = T, caption = "<center><strong>Impacto sin controles</strong></center>") %>% kable_classic_2(full_width = F, html_font = "Cambria", fixed_thead = T)

```
```{r}
# Estimación con variables significativas (desbalanceadas)

itt2<-impact_eval(data = crm,endogenous_vars =c("outcome_spend"),treatment = "mailing_indicator",
                  control_vars = var_desbal) 

itt2<-as.data.frame(itt2)
itt2<- itt2[1:2,]

kbl(itt2, booktabs = T, caption = "<center><strong>Impacto con variables significativas</strong></center>") %>% kable_classic_2(full_width = F, html_font = "Cambria", fixed_thead = T)

```
```{r}
# Estimación con variables significativas en el FDR: 
colnames(new_desbalance)<-c("variable)
desbalance_FDR<-new_desbalance$variable
itt3<-impact_eval(data = crm,endogenous_vars =c("outcome_spend"),treatment = "mailing_indicator",
                  control_vars = desbalance_FDR)

itt3<-as.data.frame(itt3)
itt3<- itt3[1:2,]

kbl(itt3, booktabs = T, caption = "<center><strong>Impacto con variables significativas FDR</strong></center>") %>% kable_classic_2(full_width = F, html_font = "Cambria", fixed_thead = T)

```
El impacto de enviar el catálogo vía email es mayor cuando no se agregan controles pero, dado que salieron desbalanceadas algunas variables, se agregan a la regresión para balancearlas. Los resultados de las dos estimaciones de robustez son muy parecidos (los coeficientes difieren por 0.02) pues la estimación que agrega las variables significativas en el FDR ya controla por las variables desbalanceadas que son relevantes. 
#### Estimación de efectos heterogeneos

Usaremos el training sample para estimar el Conditional Average Treatment Effect de enviar el catalogo sobre el gasto en dólares. Estimaremos dos tipos de modelos (si agregan otro es bienvenido): 

(a) Double Debiased LASSO
(b) Causal Forests 


\bigskip

Separa la base de entrenamiento de la de validación

#Vemos la distribución 
kable(crm%>%
        group_by(training_sample)%>%
        summarise(n =n())%>%
        mutate(share = 100*n/sum(n)), digits = 2)


##### A mí me funcionó con este otro código, lo dejo por aquí ####
#Dividimos la base:  ERES LA MEJOOOOR MARI <3 

crm_train <-subset(crm, training_sample==1)
crm_test  <- subset(crm, training_sample==0)  
  
####Double Debiased LASSO

6 (3pts). Estima un Double Debiased LASSO. Asegurate de mostrar el código. (Tip: recuerda que necesitas guardar el LASSO de cada K para poder usarlo en la base de validación)




```{r}
#Preparamos las variables :

crm_train <-
  crm_train%>%
  arrange(customer_id)

# Matriz de covariates
crm_train$training_sample<-NULL
X<-
  crm_train %>% 
  ungroup() %>%
  select(-customer_id,-mailing_indicator,-outcome_spend)
X<-sparse.model.matrix(~.+0, data = X)
dim(X)


k<-treatment_assign(data = crm_train, 
                    share_control = 0.2,n_t = 4,  
                    strata_varlist = "customer_id",
                    missfits = "global",seed = 1900, 
                    key = "customer_id")$data
View(k)
b<-k$treat
k<-
  k%>%
  mutate(k = treat+1)%>%
  ungroup()
crm_train<-bind_cols(crm_train, k%>% select(k))
k<-k$k
trat<-crm_train$mailing_indicator
outcome<-crm_train$outcome_spend


#Cross-fitting
modelo<-map_dfr(1:5,
                function(a) {
            treat_fit <-gamlr(x = X[k!=a, , drop= F],
            y =trat[k!=a],family="binomial")
                  
        treat_hat<-as.numeric(predict(treat_fit,
                  newdata = X[k==a, , drop= F],
                  type = "response"))
     
        
        outcome_fit <-gamlr(x = X[k!=a, , drop= F],
          y = outcome[k!=a])
     
        outcome_hat<-as.numeric(predict(outcome_fit,
                    newdata = X[k==a, , drop= F],
                    type = "response"))
     treat_resid <- trat[k==a]-treat_hat
  resid_outcome <- outcome[k==a]-outcome_hat
  
  fits<-bind_cols("treat_hat" = treat_hat,
                  "spend_hat"= outcome_hat,
                  "resid_treat" = treat_resid,
                  "resid_spend" = resid_outcome)
  
  })

View(modelo)


```

7 (2pts). Cuál es el impacto de tratamiento promedio? Estimalo de dos maneras: 1) `spend_resid~treat_hat + treat` y 2) `spend~treat_resid`. Sale lo mismo? Justifica tu respuesta

```{r}
# Primera forma
spend_ate1<-lm(resid_spend~treat_hat+ trat,data=modelo) 

# Segunda
spend_ate2<-lm(outcome~resid_treat, data=modelo) 

# Tercera
spend_ate3<-lm(resid_spend~resid_treat, data=modelo) 


stargazer(spend_ate1,spend_ate2,spend_ate3,type="text")
```
La estimación correcta es `spend_resid~resid_treat`, ya que en dicha especificación, tanto la Y como el tratamiento se encuentran "ortogonalizadas", es decir, libres del efecto de otras variables, por lo que se puede encontrar un impacto causal.
En la especificación 2, solo el tratamiento está ortogonalizado, por lo que podría haber otras X's que tengan impacto sobre Y.
En la especificación 1, la Y se encuentra ortogonalizada y se controla de alguna forma por el impacto de las X's sobre T (treat_hat) y por T (que se espera que aporte la parte que corresponde al tratamiento), por lo tanto, esta estimación es más parecida a la correcta.

8 (3pts). Cuáles son las variables más importantes para las nuisance functions $T_i = g(X_i)+v_i$ y $y_i=m(X_i)+\epsilon_i$? (Tip: toma las variables que tengan $\beta \neq 0$ en cada $k$ y haz un `inner_join`. De ahí muestra el promedio de los coeficientes) Interpreta la función $g(X_i)$, porque sale así?

```{r,warning=FALSE}

# g
fit_treat<-map(1:5,
                function(a) {
            treat_fit <-gamlr(x = X[k!=a, , drop=F],
            y =trat[k!=a],family="binomial")
 })

coef_g1<-as.matrix(coef(fit_treat[[1]]))
coef_g1<-tibble(variable =rownames(coef_g1),coeficiente = coef_g1[,1])
coef_g1<-coef_g1%>% filter(coeficiente!=0)

coef_g2<-as.matrix(coef(fit_treat[[2]]))
coef_g2<-tibble(variable =rownames(coef_g2),coeficiente = coef_g2[,1])
coef_g2<-coef_g2%>% filter(coeficiente!=0)

coef_g3<-as.matrix(coef(fit_treat[[3]]))
coef_g3<-tibble(variable =rownames(coef_g3),coeficiente = coef_g3[,1])
coef_g3<-coef_g3%>% filter(coeficiente!=0)

coef_g4<-as.matrix(coef(fit_treat[[4]]))
coef_g4<-tibble(variable =rownames(coef_g4),coeficiente = coef_g4[,1])
coef_g4<-coef_g4%>% filter(coeficiente!=0)

coef_g5<-as.matrix(coef(fit_treat[[5]]))
coef_g5<-tibble(variable =rownames(coef_g5),coeficiente = coef_g5[,1])
coef_g5<-coef_g5%>% filter(coeficiente!=0)
 

var_relevantes_g<-inner_join(coef_g1,coef_g2,by="variable") %>% inner_join(.,coef_g3,by="variable")%>% inner_join(.,coef_g4,by="variable")%>% inner_join(.,coef_g5,by="variable")

colnames(var_relevantes_g) <- c("Variable","F1","F2","F3","F4","F5")               
var_relevantes_g$promedio <- with(var_relevantes_g, (F1+F2+F3+F4+F5)/5 )

# m
fit_outcome<-map(1:5,
                function(a) {
            outcome_fit <-gamlr(x = X[k!=a, , drop= F],
            y = outcome[k!=a])
 })

coef_m1<-as.matrix(coef(fit_outcome[[1]]))
coef_m1<-tibble(variable =rownames(coef_m1),coeficiente = coef_m1[,1])
coef_m1<-coef_m1%>% filter(coeficiente!=0)

coef_m2<-as.matrix(coef(fit_outcome[[2]]))
coef_m2<-tibble(variable =rownames(coef_m2),coeficiente = coef_m2[,1])
coef_m2<-coef_m2%>% filter(coeficiente!=0)

coef_m3<-as.matrix(coef(fit_outcome[[3]]))
coef_m3<-tibble(variable =rownames(coef_m3),coeficiente = coef_m3[,1])
coef_m3<-coef_m3%>% filter(coeficiente!=0)

coef_m4<-as.matrix(coef(fit_outcome[[4]]))
coef_m4<-tibble(variable =rownames(coef_m4),coeficiente = coef_m4[,1])
coef_m4<-coef_m4%>% filter(coeficiente!=0)

coef_m5<-as.matrix(coef(fit_outcome[[5]]))
coef_m5<-tibble(variable =rownames(coef_m5),coeficiente = coef_m5[,1])
coef_m5<-coef_m5%>% filter(coeficiente!=0)


var_relevantes_m<-inner_join(coef_m1,coef_m2,by="variable") %>% inner_join(.,coef_m3,by="variable")%>% inner_join(.,coef_m4,by="variable")%>% inner_join(.,coef_m5,by="variable")

colnames(var_relevantes_m) <- c("Variable","F1","F2","F3","F4","F5")               
var_relevantes_m$promedio <- with(var_relevantes_m, (F1+F2+F3+F4+F5)/5 )      
  
```
Solo el intercepto sale relevante para g(x), mientras que para m(x) hay 39 variables relevantes (incluyendo el intercepto). Por lo tanto, parece que el tratamiento es ortogonal a las X's.

9 (3pts). Ahora corre un DDML LASSO para encontrar los efectos a nivel cliente (Tip: interactúa todas las variables con `treat_resid`. Muestra el código. Qué varaibles salen significativas?

```{r,warning=FALSE}

## Generamos una matriz X sparse,que incluye resid_treat y las interacciones de x con resid_treat

# Generamos X nuevamente
crm_train <- subset(crm, training_sample==1)
X1<-crm_train%>%ungroup()%>%select(-customer_id,-mailing_indicator,-outcome_spend)
# Agregamos resid_treat

T_resid<-modelo$resid_treat
X1$resid_treat<-with(X1,T_resid)

# Matriz sparse con interacciones
X1<-sparse.model.matrix(~.+0+resid_treat*., data = X1)

## Generamos Y
Y<-modelo$resid_spend

## LASSO 
lasso_hte<-gamlr(x = X1, y =Y)
       
coef_lasso_hte<-as.matrix(coef(lasso_hte))
coef_lasso_hte<-tibble(variable =rownames(coef_lasso_hte),coeficiente = coef_lasso_hte[,1])
coef_lasso_hte<-coef_lasso_hte%>% filter(coeficiente!=0)

```
Salen 60 interacciones significativas.

10 (2 pts). Predice el CATE en la base de entrenamiento y en la base de validación. Como se ve la distribución del impacto de tratamiento en ambas? 

```{r,warning=FALSE}

## En la base de entrenamiento
pred_train<-as.numeric(predict(lasso_hte, newdata=X1, type="response"))
pred<-as.data.frame(pred_train)
colnames(pred)<-"Impacto"


## En la base de validación

# Generamos matrices

crm_test$training_sample<-NULL

Xv<-crm_test%>%ungroup()%>%select(-customer_id,-mailing_indicator,-outcome_spend)
Xv<-sparse.model.matrix(~.+0, data = Xv)

tratv<-crm_test$mailing_indicator
outcomev<-crm_test$outcome_spend

# Predecimos scores de g y m en la base de validación
   # g
pred_g1<-as.numeric(predict(fit_treat[[1]], newdata=Xv, type="response"))
pred_g1<-as.data.frame(pred_g1)

pred_g2<-as.numeric(predict(fit_treat[[2]], newdata=Xv, type="response"))
pred_g2<-as.data.frame(pred_g2)

pred_g3<-as.numeric(predict(fit_treat[[3]], newdata=Xv, type="response"))
pred_g3<-as.data.frame(pred_g3)

pred_g4<-as.numeric(predict(fit_treat[[4]], newdata=Xv, type="response"))
pred_g4<-as.data.frame(pred_g4)

pred_g5<-as.numeric(predict(fit_treat[[5]], newdata=Xv, type="response"))
pred_g5<-as.data.frame(pred_g5)


treat_hatv<-cbind.data.frame(pred_g1,pred_g2,pred_g3,pred_g4,pred_g5)
treat_hatv$promedio<-with(treat_hatv,(pred_g1+pred_g2+pred_g3+pred_g4+pred_g5)/5)
treat_residv <- as.data.frame(tratv-treat_hatv$promedio)
colnames(treat_residv)<-"treat_residv"
  # m

pred_m1<-as.numeric(predict(fit_outcome[[1]], newdata=Xv, type="response"))
pred_m1<-as.data.frame(pred_m1)

pred_m2<-as.numeric(predict(fit_outcome[[2]], newdata=Xv, type="response"))
pred_m2<-as.data.frame(pred_m2)

pred_m3<-as.numeric(predict(fit_outcome[[3]], newdata=Xv, type="response"))
pred_m3<-as.data.frame(pred_m3)

pred_m4<-as.numeric(predict(fit_outcome[[4]], newdata=Xv, type="response"))
pred_m4<-as.data.frame(pred_m4)

pred_m5<-as.numeric(predict(fit_outcome[[5]], newdata=Xv, type="response"))
pred_m5<-as.data.frame(pred_m5)


outcome_hatv<-cbind.data.frame(pred_m1,pred_m2,pred_m3,pred_m4,pred_m5)
outcome_hatv$promedio<-with(outcome_hatv,(pred_m1+pred_m2+pred_m3+pred_m4+pred_m5)/5)
spend_residv <- as.data.frame(outcomev-outcome_hatv$promedio)
colnames(spend_residv)<-"spend_residv"

## Generamos una matriz X sparse,que incluye treat_residv y las interacciones de x treat_residv

# Generamos X nuevamente
crm_test <- subset(crm, training_sample==0)
Xlasso<-crm_test%>%ungroup()%>%select(-customer_id,-mailing_indicator,-outcome_spend)

# Agregamos resid_treatv

Xlasso$resid_treatv<-with(Xlasso,treat_residv$treat_residv)

# Matriz sparse con interacciones
Xlasso<-sparse.model.matrix(~.+0+resid_treatv*., data = Xlasso)

# Generamos Y
Yv<-spend_residv$spend_residv

## LASSO 
lasso_htev<-gamlr(x = Xlasso, y =Yv)

pred_test<-as.numeric(predict(lasso_htev, newdata=Xlasso, type="response"))
predv<-as.data.frame(pred_test)
colnames(predv)<-"Impacto_val"
hist(predv$pred_test)

```

CATE training

```{r}
summary(pred$Impacto)

```

CATE validación

```{r}
summary(predv$Impacto_val)

```



####Causal Forest

11 (2pts). Ahora vayamos al causal forest. Estima un causal forest en la base de entrenamiento (Estima 750 árboles)
```{r cache=TRUE}
crm_train <- subset(crm, training_sample==1)
X<-
  crm_train %>% 
  ungroup() %>%
  select(-customer_id,-mailing_indicator,-outcome_spend)
X<-sparse.model.matrix(~.+0, data = X)
Y<-crm_train$outcome_spend
W<-crm_train$mailing_indicator

library(parallel)


detectCores()
cl<-makeCluster(8)
inicio<-Sys.time()

#Estimamos causal forest
cf<-causal_forest(X,Y,W, num.trees = 750)
(tiempo<-Sys.time()-inicio)

stopCluster(cl)


```
12 (3pts). Cómo se distribuye el impacto de tratamiento? Cuál es el impacto de tratamiento (ATE)? Qué tanto se acerca al impacto de tratamiento "real"? Cómo se compara con el impacto estimado con el ddml simple?

```{r}

average_treatment_effect(
  cf, method = c("AIPW"),
  subset = NULL)


```
ATE=2.7610950

13. Haz un scatter plot de las predicciones de ambos modelos? Hay alguna relación?
```{r}
# Forest
cf_pred<-cf$predictions


plot(cf_pred, main="Predicción Causal Forest", xlab="")
```

```{r}
# DD LASSO

plot(predv$Impacto_val,main="Predicción lasso",xlab="")

```

14 (4pts). Evalúa el poder predictivo de cada modelo (OOS). Esto se hace por modelo: Divide la muestra en 10 partes con base en el score de ddml. Para cada parte, estima el impacto de tratamiento vía una regresión y saca el promedio del score. Valida si para los grupos que dice el score el impacto será más grande, el coeficiente de la regresión es. Cómo se ven los modelos? Cuál parece ser mejor?

```{r}
#Dividimos la muestra en deciles partes con base al score de ddml

library(gtools)
d <- quantcut(modelo$spend_hat, c(0,.1,.2,.3,.4,.5,.6,.7,.8,.9, 1))
crm_lasso<-split(modelo, d)
p1<-crm_lasso$`[-22.2,-0.00286]`
p2<-crm_lasso$`(-0.00286,0.854]`
p3<-crm_lasso$`(0.854,1.6]`
p4<-crm_lasso$`(1.6,2.54]`
p5<-crm_lasso$`(2.54,3.73]`
p6<-crm_lasso$`(3.73,5.35]`
p7<-crm_lasso$`(5.35,7.7]`
p8<-crm_lasso$`(7.7,11.5]`
p9<-crm_lasso$`(11.5,19.7]`
p10<-crm_lasso$`(19.7,832]`

ate1_lasso<-lm(resid_spend~resid_treat, data=p1)
a1<-ate1_lasso$coefficients[2]
ate2_lasso<-lm(resid_spend~resid_treat, data=p2)
a2<-ate2_lasso$coefficients[2]
ate3_lasso<-lm(resid_spend~resid_treat, data=p3)
a3<-ate3_lasso$coefficients[2]
ate4_lasso<-lm(resid_spend~resid_treat, data=p4)
a4<-ate4_lasso$coefficients[2]
ate5_lasso<-lm(resid_spend~resid_treat, data=p5)
a5<-ate5_lasso$coefficients[2]
ate6_lasso<-lm(resid_spend~resid_treat, data=p6)
a6<-ate6_lasso$coefficients[2]
ate7_lasso<-lm(resid_spend~resid_treat, data=p7)
a7<-ate7_lasso$coefficients[2]
ate8_lasso<-lm(resid_spend~resid_treat, data=p8)
a8<-ate8_lasso$coefficients[2]
ate9_lasso<-lm(resid_spend~resid_treat, data=p9)
a9<-ate9_lasso$coefficients[2]
ate10_lasso<-lm(resid_spend~resid_treat, data=p10)
a10<-ate10_lasso$coefficients[2]
  
(prom_ate_lasso<-(a1+a2+a3+a4+a5+a6+a7+a8+a9+a10)/10)

#Causal Forest 

crm_cf<-data.frame(
  "resid_spend" = cf$Y.orig-cf$Y.hat, 
  "resid_treat" = cf$W.orig-cf$W.hat,
  "spend_hat" = cf$Y.hat)


c <- quantcut(crm_cf$spend_hat, c(0,.1,.2,.3,.4,.5,.6,.7,.8,.9, 1))
crm_cfo<-split(crm_cf, c)


c1<-crm_cfo$`[0.645,1.39]`
c2<-crm_cfo$`(1.39,1.86]`
c3<-crm_cfo$`(1.86,2.43]`
c4<-crm_cfo$`(2.43,3.17]`
c5<-crm_cfo$`(3.17,4.12]`
c6<-crm_cfo$`(4.12,5.42]`
c7<-crm_cfo$`(5.42,7.31]`
c8<-crm_cfo$`(7.31,10.5]`
c9<-crm_cfo$`(10.5,17.5]`
c10<-crm_cfo$`(17.5,328]`

ate1_c<-lm(resid_spend~resid_treat, data=c1)
ac1<-ate1_c$coefficients[2]
ate2_c<-lm(resid_spend~resid_treat, data=c2)
ac2<-ate2_c$coefficients[2]
ate3_c<-lm(resid_spend~resid_treat, data=c3)
ac3<-ate3_c$coefficients[2]
ate4_c<-lm(resid_spend~resid_treat, data=c4)
ac4<-ate4_c$coefficients[2]
ate5_c<-lm(resid_spend~resid_treat, data=c5)
ac5<-ate5_c$coefficients[2]
ate6_c<-lm(resid_spend~resid_treat, data=c6)
ac6<-ate6_c$coefficients[2]
ate7_c<-lm(resid_spend~resid_treat, data=c7)
ac7<-ate7_c$coefficients[2]
ate8_c<-lm(resid_spend~resid_treat, data=c8)
ac8<-ate8_c$coefficients[2]
ate9_c<-lm(resid_spend~resid_treat, data=c9)
ac9<-ate9_c$coefficients[2]
ate10_c<-lm(resid_spend~resid_treat, data=c10)
ac10<-ate10_c$coefficients[2]
  
(prom_ate_cf<-(ac1+ac2+ac3+ac4+ac5+ac6+ac7+ac8+ac9+ac10)/10)


tabla_c<-cbind(prom_ate_cf,prom_ate_lasso)

tabla_c %>%
kbl(booktabs = T,
      caption = "Tabla 2: Evaluación del Poder Predictivo del modelo")%>%
  kable_material(c("striped", "hover"))

```


15 (6 pts). Construye una estrategia de focalización a nivel usuario con base a los resultados de cada modelo. Considera lo siguiente: 

- El costo marginal de mandar el mail es 0.99 USD 

- El Beneficio marginal es el impacto incremental la utilidad generada por esas ventas 

- El margen de ganancia sobre las ventas es de 32.5 fijo 

Con esto, indica: 

- Cuantos usuarios entrarían a la campaña? 

- A partir de cuánto lift (ventas incrementales) entran? 

- Cuál es el impacto promedio esperado de tu población final? 

- Cuánta utilidad haremos con esta estrategia? Cómo se compara con la utilidad de la campaña sin focalizar?




16 (3pts). Haz una gráfica del la utilidad total vs q (personas que entran en la campaña) para DDML y CF


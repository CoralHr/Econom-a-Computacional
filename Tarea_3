---
title: "Diseño y Evaluación de RCTs"
author: "Isidoro Garcia"
date: "2021"
output: pdf_document
urlcolor: blue
graphics: yes
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA, message = FALSE,
                      fig.width = 7, fig.height = 4, fig.align = "right")
```

```{r, warning=FALSE}
library(tidyverse)
library(data.table)
library(broom)
library(knitr)
library(lubridate)
library(RCT)
```



## Contexto

Rappi te contrata para hacer una intervención que active a sus usuarios en la plataforma. La empresa quiere evaluar si es necesario darles cash a los usuarios (y cuánto) para reactivar a los usuarios o si es suficiente con una campaña informativa. 

Para ello, te decides a realizar un experimento factorial donde evalúas: 

- El impacto de mandar un mensaje informativo donde muestres las nuevas tiendas afiliadas a Rappi, y 

- El impacto de dar 100, 200 o 300 pesos en cupones

Finalmente, les gustaría entender cómo interactuar el mostrar las nuevas tiendas aunado con dar dinero en cupones. 

A la empresa le gustaría entender el impacto de la intervención sobre: 

- Las compras 

- La tasa de usuarios activos en la app (transaccionar: abrir app o hacer compras)

\newpage

## Datos

Los datos para asignar los pueden encontrar en `universo.Rdata`. 

Cargemos los datos
```{r }
load("C:/Users/coral/Desktop/Maestría_2/ECONOMIA_COMPU/universo.Rdata")
attach(universo)
View(universo)

```

### 1. Cuántos grupos de tratamiento debe de haber? Elabora sobre que intervención va a recibir cada uno 

- Control: Ninguna intervención

- Trat 1: Sólo mensaje

- Treat 2: Sólo cupón de $100

- Treat 3: Sólo cupón de $200

- Treat 4: Sólo cupón de $300

- Treat 5: Mensaje + cupón de $100

- Treat 6: Mensaje + cupón de $200

- Treat 7: Mensaje + cupón de $300



### 2 (2pts). Como pueden notar, tenemos 2 poblaciones: Usuarios inactivos y usuarios que nunca estuvieron activos. Para ellos, las tasas de transaccionalidad son hasta ahora 7.94% y 0%. Utiliza esta información para hacer pruebas de poder: Dada esta tasa y población, cuál es el efecto mínimo detectable sobre la tasa de transaccionalidad como función de cuantas observaciones asignamos al grupo control? Interpreta. (Tip: asegurate de dejar claros los grupos comparados en esta prueba)
```{r, results='asis', echo=FALSE,warning=FALSE, message=FALSE}
# Convertimos la variable population a factor para conocer el tamaño de cada grupo (Inactive, Never Active)
universo$population<-factor(universo$population)
summary(universo$population)
# Se obtienen 14084 individuos inactive y 90107 inactive, con lo cual se puede estimar la tasa de transaccionalidad, a partir de las tasas que conocemos para cada grupo (7.94 y 0)
p_y<-0.0794*(14084/194191)+0*(90107/194191)
(tau2<-tau_min_probability(p_y,N=nrow(universo),share_control = seq(0,1,0.05),n_groups=8))
stargazer(tau2,type="latex",summary=FALSE,font.size="tiny")
```
### 3. Repite el mismo ejercicio pero ahora para usando las compras totales como variable objetivo. Elige un share de control con base en tu respuesta de esta y la anterior pregunta

```{r, results='asis', echo=FALSE, warning=FALSE, message=FALSE}
(tau3<-tau_min(universo$total_purchases,N=nrow(universo),share_control = seq(0,1,0.05),n_groups=8))
stargazer(tau3,type="latex",summary=FALSE, font.size="tiny")
```
# Con base en la respuesta a las preguntas 2 y 3, se observa que el efecto mínimo detectable para cada tratamiento se minimiza con un share de control entre 0.25 y 0.3. Se elige 0.3, que tiene un menor efecto mínimo detectable global.

#PROPONGO:
# Como podemos observar en la tabla, el efecto mínimo detectable por cada grupo de tratamiento es "0.002398075" tanto si se elige un share de control de 30% como de 25%. 
Pero podemos notar una diferencia casi nula en el efecto mínimo detectable global, que nos da un valor de  0.0015 y 0.0014 respectivamente. 
Normalmente en los experimentos intentamos tener el menor porcentaje posible en el grupo de control, añadiendo que contamos con un número considerable de población para realizar el experimento.




### 4 (2ptos) Qué variables crees que puedan estar más correlacionadas con el impacto? Justifica tu respuesta y elige un set

Edad, género y tipo de población podrían estar más correlacionadas con el impacto de tratamiento. 
En particular, las personas de distinta edad podrían reaccionar distinto al hecho de recibir el mensaje o recibir cupones; por ejemplo, a los más jóvenes podría darles flojera leer sobre las nuevas tiendas afiliadas pero podrían reaccionar mejor al recibir cupones (ya que podrían tener un presupuesto más limitado para gastar a través de la app, que las personas de mayor edad). 
También hombres y mujeres podrían reaccionar diferente a recibir el mensaje pues podría ser que alguno de ellos, por ejemplo, las mujeres, se encarguen más frecuentemente de realizar las compras, por lo que están más familiarizadas con las tiendas disponibles en la app y reaccionen mejor ante el conocimiento de nuevas tiendas que se agregan.  
Por otra parte, el tipo de población de que se trate (never active o unactive) también puede estar muy relacionado con el impacto, pues se esperaría que haya un mayor impacto para aquellos que han estado activos alguna vez vs los que nunca han estado activos, quienes tendrían una "barrera" de uso mayor.

```{r }

#Volvemos las variables categoricas a numéricas para poder correr el colerrograma 
datos_num<-universo%>%select(-user_id)

datos_num$population<-as.factor(datos_num$population)
datos_num$population<-ifelse(datos_num$population=="Inactive",1,0)


datos_num$device_value_d <-ifelse(datos_num$device_value== "[$0-$10,000]" , 1,
                  ifelse(datos_num$device_value== "[$10,001+]", 2, 
                  ifelse(datos_num$device_value== "No info", 3,0)))

# Transformo mis variables a numéricas para el correlograma
library(corrplot)

a<-cor(datos_num  %>% select(-device_value))

corrplot(a, method="number")


```


###PROPONGO
Añadir la varible de de verificación de teléfono ya que los usuarios que verifican su teléfono pueden tener una relación muy marcada con el impacto, 
porque pueden tener más interés en realizar compras que aquellos que no lo verifican.

También se puede notar en el correlograma que las variables más relacionadas con el total de compras son: edad, 

### 5 (2ptos) Realiza la asignación aleatoria. Muestra la distribución de los grupos por estrato, los misfits. Sin mirar el balance, lograron una asignación aleatoria exitosa? Justifica tu respuesta 
```{r }
attach(universo)

#Generamos grupos de tratamiento y control a través de una asignación aleatoria estratificada por género, edad y tipo de población. 

```{r, results='asis', echo=FALSE, warning=FALSE, message=FALSE}
# Convertimos age en cuartiles
universo$agelabel<-ntile_label(universo$age,n=4)
# Realizamos la asignación
assignment<-treatment_assign(data = universo, share_control = 0.3, n_t = 7, strata_varlist =dplyr::vars(agelabel, gender_F, population), missfits="NA", seed = 1990, key = "user_id")
tabla<-as.data.frame(assignment$summary_strata)
stargazer(tabla,type="latex",summary=FALSE)

```
Sin mirar el balance no podemos saber si se trató de una asignación aleatoria exitosa porque no podemos evaluar unconfoundness/excludability, pero al menos sabemos que hay balance en términos de las variables por las que estratificamos.
### 6. Qué elección tomaron sobre como manejar los misfits? Elaboren sus razones
Como solo se encontraron 91 missfits, que representan el 0.08% de las observaciones, se optó por eliminarlos del experimento. 


### 7. Realiza las pruebas de balance t sobre todas las variables (Tip: transforma las categóricas en dummys). Parece haber balance?  
```{r, results='asis', echo=FALSE, warning=FALSE, message=FALSE}
load("d:/Users/marisol.nava/Desktop/Maestría/Eco_computacional/Tarea_3/universo.Rdata")

# Las pruebas se realizan sobre todas las variables observables
# Creamos dummies
library(fastDummies)
universo_dum<-dummy_cols(universo,select_columns = c("device_value", "phone_verified","population","gender_F"),remove_first_dummy = FALSE,remove_selected_columns = TRUE)

# Agregamos variable de asignación al tratamiento
base<-as.data.frame(assignment$data)

universo_dum<-merge(universo_dum,base, by="user_id")

#Eliminamos user_id, strata, missfit y na's
universo_dum<-universo_dum[,-1]
universo_dum<-universo_dum[,-13]
universo_dum<-universo_dum[,-14]
universo_dum<-universo_dum[!is.na(universo_dum$treat),]

tabla_b<-balance_table(universo_dum,"treat")
stargazer(as.data.frame(tabla_b),type="latex",summary=FALSE, keep=c(2,11:17))

#otra forma de ver la tabla: 
tabla_d %>%
  kbl(booktabs = T,
      caption = "Tabla 1: Aleatoriedad del instrumento")%>%
  kable_material(c("striped", "hover"))
                            
```
En general parece haber balance, pues con un 5% de significancia, solo hay 5 de 84 pruebas t que se rechazan. Sin embargo, hay 2 variables (device_value_[0-10,000] y device_value_No info) que concentran 4 de esas pruebas, por lo que podrían estar desbalanceadas.
En la evaluación de este experimento, se podrían incluir dichas variables, para asegurarnos de recuperar el balance.
 
### 8. Repite el ejercicio pero ahora con pruebas de balance conjuntas. Muestra los resultados (incluyendo el estadístico de prueba, grados de libertad y p values) Interpreta

```{r, results='asis', echo=FALSE, warning=FALSE, message=FALSE}

balance_r<-balance_regression(universo_dum,"treat")
efe<-balance_r$F_test
stargazer(as.data.frame(efe),type="latex",summary=FALSE, font.size = "small")

```
Todos los valores p son suficientemente grandes, por lo que en ninguno de los grupos se rechaza la hipótesis de que las covariables no explican la Pr de pertenecer al tratamiento, lo cual nos da evidencia de que la asignación es aleatoria.
### 9. Elabora por qué parecen cumplirse los 3 supuestos de la asignación


```{r, results='asis', echo=FALSE, warning=FALSE, message=FALSE}

datos<-as.data.frame(assignment$data)
table(datos$treat, useNA = "ifany")
prop.table(table(datos$treat, useNA = "ifany"))



```
Parece que se cumplen los tres supuestos, ya que: 
SUTVA: Estamos asignando tratamientos a nivel individual (mensajes a sus dispositivos privados y dinero que pueden utilizar en su cuenta); no se está considerando realizar algún otro esfuerzo de publicidad, por ejemplo, en medios masivos, lo que evita que el grupo de control se entere de la información que se les dio a los individuos tratados o que los grupos de control se enteren del dinero que se les ofreció a otros grupos (lo que podría hacerles cambiar su comportamiento). Por lo tanto, no parece hacer fuentes de contaminación que impidan que se cumpla este supuesto.  
Overlap: Podemos observar que las probabilidades de cada individuo de pertenecer a algún grupo de tratamiento están entre 0 y 1 (sin incluirlos). 
Unconfoundness: Las pruebas de balance anteriores, en particular, la prueba de balance conjunta, dan evidencia de que los grupos se encuentran balanceados, por lo que parece que la aleatorización funcionó y que no existe relación entre la asignación de tratamiento y las características (observables) de los individuos.

### 10. Elabora un pitch de negocio sobre los beneficios que este experimento podría dejar a Rappi. 

Si realizamos el experimento propuesto, podríamos conocer qué incentivos son mejores para que los clientes se activen en la plataforma, de tal manera que se utilice la estrategia menos costosa. Además, obtendríamos información de cómo focalizar los incentivos, para obtener la respuesta más alta posible haciendo un uso óptimo de los recursos disponibles. Con esto, se podría generar una estrategia que permita a Rappi una mayor activación de sus usuarios y establecerse como una opción clara cuando se hable de compras a través de apps.


## Evaluación 

Pasemos a la evaluación de tu intervención. En este ejercicio, Rappi diseñó un nuevo experimento con tus enseñanzas algo distinto al tuyo. 

Este consistió en 6 grupos de tratamiento y un control:

- T1: Dar 100 pesos en cupones (con mensaje)

- T2: Dar 200 pesos en cupones (con mensaje)

- T3: Dar un descuento de 20% en la siguiente compra 

- T4: Dar un descuento de 25% en la siguiente compra

- T5: Ofrecer 2% de descuento en la siguiente compra por cada usuario que refieran

- T6: Ofrecer 4% de descuento en la siguiente compra por cada usuario que refieran


Te piden ahora medir este experimento (estratificado por `phone_verified`, `population` y `device_value`) en la base
`base_evaluacion.Rdata`. Las variables endogenas son `total_purchases_after` que refleja el gasto total post-tratamiento y `transacted` que refleja abrir la app o hacer compras. 


Carguemos la base 

```{r }
rm(list = ls())

load("d:/Users/marisol.nava/Desktop/Maestría/Eco_computacional/Tarea_3/base_evaluacion.Rdata")


```

### 10 (2ptos). Muestra el estimador ITT para la tasa de transaccionalidad. Recuerda que tu cliente es un grupo empresarial. Por ende, muestra una gráfica donde se aprecie la diferencia entre los grupos de tratamiento y las significancias de manera sencilla. Interpreta tus resultados 

```{r }
#Elaboremos una tabla de balance para revisar nuestro supuesto de unconfoundness y revisar si tendríamos que aumentar alguna variable para volver más eficiente nuestra regresión: 
#para dicotómicas 
universo_f_d<-universo_f%>%select(-user_id,-treat2,-total_purchases_after,-strata,-missfit,-logtotal_p,-transacted)

#Volvemos factores algunas variables:
universo_f_d<-dummy_cols(universo_f_d,select_columns = c("device_value","age_median", "phone_verified","population","gender_F"),remove_first_dummy = FALSE,remove_selected_columns = TRUE)


tabla_c<-balance_table(universo_f_d,"treat")
library(kableExtra)
library(knitr)
tabla_c %>%
  kbl(booktabs = T,
      caption = "Tabla 1: Aleatoriedad del instrumento") %>%
  kable_material(c("striped", "hover"))


```


```{r, results='asis', echo=FALSE}

eval10<-impact_eval(data=universo_f,endogenous_vars="transacted",treatment="treat")
eval10<-as.data.frame(eval10)
eval10$nombre<-c("Control","Trat1","Trat2","Trat3","Trat4","Trat5","Trat6")

ggplot2::ggplot(data=eval10,aes(x=nombre, y=transacted.estimate, fill=rownames(eval10)))+geom_bar(stat="identity")+guides(fill=FALSE)+labs(x="Tratamientos", y="transacting rate")+geom_text(aes(label=scales::percent(transacted.estimate)))

```
El ITT sobre la tasa de transaccionalidad es mayor para quienes recibieron el tratamiento 4 (impacto de 10 puntos porcentuales), que consistió en dar un descuento de 25% en la siguiente compra, seguido de los que recibieron el tratamiento 6 (impacto de 7 puntos porcentuales), que consistió en un 4% de descuento por usuario referido.

### 11. Repite el ejercicio sobre compras totales. Que resultados se aprecian? Que indica esto sobre la rentabilidad del sistema de incentivos? 
```{r, results='asis', echo=FALSE}

eval11<-impact_eval(data=universo_f,endogenous_vars="total_purchases_after",treatment="treat")
eval11<-as.data.frame(eval11)
eval11$nombre<-c("Control","Trat1","Trat2","Trat3","Trat4","Trat5","Trat6")

ggplot2::ggplot(data=eval11,aes(x=nombre, y=total_purchases_after.estimate, fill=rownames(eval11)))+geom_bar(stat="identity")+guides(fill=FALSE)+labs(x="Tratamientos", y="gasto total")+geom_text(aes(label=round(total_purchases_after.estimate,digits=2)))

```
Cuando se repite el ejercicio pero esta vez con el gasto total post-tratamiento podemos notar que solo los tratamientos "BTC 100" y "USD 200" reportan un gasto total promedio mayor que aquellos usuarios que no recibieron incentivos. Sin embargo ninguna de estas estimaciones es estadísticamente significativa.


### 12. Interpreta el impacto del gruop de referidos 4%. Porque el estimador es tan diferente y a la vez es no significativo? Por que esto no paso en la tasa de transaccionalidad?
Esto sucedió debido a la variación tan grande que existe entre los distintos gastos en los diversos estímulos a los usuarios, de igual forma esta variación afecto la significancia.


### 13 (2ptos). Repite la medición en 11 pero ahora con `log(total_purchases_after+1)`. Que encuentras ahora? Interpreta las diferencias

```{r, results='asis', echo=FALSE}
universo_f$logtotal_p<-log(universo_f$total_purchases_after+1)

eval13<-impact_eval(data=universo_f,endogenous_vars="logtotal_p",treatment="treat")
eval13<-as.data.frame(eval13)
eval13$nombre<-c("Control","Trat1","Trat2","Trat3","Trat4","Trat5","Trat6")

ggplot2::ggplot(data=eval13,aes(x=nombre, y=logtotal_p.estimate, fill=rownames(eval13)))+geom_bar(stat="identity")+guides(fill=FALSE)+labs(x="Tratamientos", y="log gasto total")+geom_text(aes(label=round(logtotal_p.estimate,digits=2)))

```
En esta tercera estimación se ocuparon los logaritmos del gasto total post-tratamiento con la finalidad de reducir la sensibilidad de las estimaciones a las observaciones extremas o atípicas, de tal forma que a diferencia del resultado anterior ahora todas las estimaciones son estadísticamente significativas a un 99%



### 14 (4ptos). Describre que variables necesitas para hacer un análisis costo beneficio completo. Les doy algunas: Ticket promedio $100, Customer Lifetime value: $1,100. Con esto, que sistema de incentivos recomendarías? Porqué? Muestra el razonamiento detrás de tu recomendación


### 15 (2ptos). Realiza la estimación de efectos heterogeneos para ambas variables usando `population`. Que encuentras? existe alguna subpoblación para la que los efectos difieran del promedio? Para cada efecto, muestra gráficas como lo hiciste en los ITTs
```{r, results='asis', echo=FALSE}

# Efectos heterogéneos para transaccionalidad

eval15<-impact_eval(data=universo_f,endogenous_vars="transacted",treatment="treat",heterogenous_vars="population")
eval15transpop<-eval15$transacted_population
eval15transpop$nombre<-c("Control","Trat1","Trat2","Trat3","Trat4","Trat5","Trat6","Control","Trat1","Trat2","Trat3","Trat4","Trat5","Trat6")
eval15_df<-as.data.frame(eval15transpop)

ggplot2::ggplot(data=eval15_df,aes(x=nombre, y=estimate, fill=rownames(eval15_df)))+geom_bar(stat="identity")+guides(fill=FALSE)+labs(x="Tratamientos", y="transacting rate")+geom_text(aes(label=round(estimate,digits=2)))+facet_wrap(~population)

```{r, results='asis', echo=FALSE}

#para gasto total:
eval16<-impact_eval(data=universo_f,endogenous_vars="total_purchases_after",treatment="treat",heterogenous_vars="population")
eval16total_pur<-eval16$total_purchases_after_population
eval16total_pur$nombre<-c("Control","Trat1","Trat2","Trat3","Trat4","Trat5","Trat6","Control","Trat1","Trat2","Trat3","Trat4","Trat5","Trat6")
eval16_df<-as.data.frame(eval16total_pur)

ggplot2::ggplot(data=eval16_df,aes(x=nombre, y=estimate, fill=rownames(eval16_df)))+geom_bar(stat="identity")+guides(fill=FALSE)+labs(x="Tratamientos", y="gasto total")+geom_text(aes(label=round(estimate,digits=2)))+facet_wrap(~population)


```



### 16 (2ptos). Repite el ejercicio para ``phone_verified`. 

```{r, results='asis', echo=FALSE}
# Efectos heterogéneos para transaccionalidad

universo_f$phone_verified<-factor(universo_f$phone_verified)
eval16t<-impact_eval(data=universo_f,endogenous_vars="transacted",treatment="treat",heterogenous_vars="phone_verified")

eval16t<-eval16t$transacted_phone_verified
eval16t$nombre<-c("Control","Trat1","Trat2","Trat3","Trat4","Trat5","Trat6","Control","Trat1","Trat2","Trat3","Trat4","Trat5","Trat6")
eval16t_df<-as.data.frame(eval16t)

ggplot2::ggplot(data=eval16t_df,aes(x=nombre, y=estimate, fill=rownames(eval16t_df)))+geom_bar(stat="identity")+guides(fill=FALSE)+labs(x="Tratamientos", y="transacting rate")+geom_text(aes(label=round(estimate,digits=2)))+facet_wrap(~phone_verified)

# Para gasto total 

eval18<-impact_eval(data=universo_f,endogenous_vars="total_purchases_after",treatment="treat",heterogenous_vars="phone_verified")
eval18total_pur<-eval18$total_purchases_after_phone_verified
eval18total_pur$nombre<-c("Control","Trat1","Trat2","Trat3","Trat4","Trat5","Trat6","Control","Trat1","Trat2","Trat3","Trat4","Trat5","Trat6")
eval18_df<-as.data.frame(eval18total_pur)

ggplot2::ggplot(data=eval18_df,aes(x=nombre, y=estimate, fill=rownames(eval18_df)))+geom_bar(stat="identity")+guides(fill=FALSE)+labs(x="Tratamientos", y="gasto total")+geom_text(aes(label=round(estimate,digits=2)))+facet_wrap(~phone_verified)


```

### 17. Presenta una propuesta de focalización con base en tus resultados generales y heterogeneos. 
